
<h1 align="center">Volt</h1>

<p align="center">
  Code Agent â€“ writing apps locally, mostly with Qwen.
</p>


### Local LLMs

- Ollama server (required)
- Qwen models by Alibaba (optional)
- Deepseek R1 (pending)

  ğŸ“: (`qwen2.5-coder:7b` is currently hardcoded in `actions.tsx`)


### Current build

  ğŸ“: (Select an Ollama model before prompting the agent!)

- Next.js app router with React/Tailwind
- Some components from Llamacoder
- Code sandbox by Sandpack

- Token stats & app settings by [nexaforge-dev](https://github.com/ageborn-dev/nexaforge-dev)


### Features

- Code + Preview frames
- Chat, Settings & Token frames (WIP)

  ğŸ“: (System prompt preset for React-based `App.tsx`)
  

### Prep / Planning

  ğŸ“: (Works in progress)

- ğŸ”Œ:  dark mode
- ğŸ”Œ:  draggable frames
- ğŸ”Œ:  remember chosen model
- ğŸ”Œ:  thinking frame for Deepseek R1


### Cloning & running

1. Clone repo: `git clone https://github.com/kontains/volt`
2. Start [Ollama](https://github.com/ollama/ollama/releases/) server on your machine.
3. Run `npm install --legacy-peer-deps` then `npm run dev` to start locally.
4. Go to `http://localhost:3000/?t=1` in your browser.

   ğŸ“: (Defaults to first available port after 3000 if busy)


### Contributing

- currently a WIP.
- Issues and PRs are open.
- [![Discord](https://img.shields.io/discord/416779691525931008?color=%237289da&label=Discord)](https://discord.gg/zGn7MS6) 

---

(sample)

[![ui-dark](https://github.com/kontains/volt/blob/main/assets/img/update.jpg)](https://github.com/kontains/volt)

---


